# ğŸš€ Quick Start - Web Crawler em Go

## ğŸ“¦ InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Instalar dependÃªncias
go get github.com/PuerkitoBio/goquery
go get golang.org/x/time/rate

# 2. Testar se estÃ¡ funcionando
go run cmd/aula-crawler/01-basico/main.go
go run cmd/aula-crawler/02-concorrente/main.go
go run cmd/aula-crawler/03-completo/main.go
```

---

## ğŸ“ Ordem de Aprendizado

### 1ï¸âƒ£ Exemplo BÃ¡sico (15 minutos)
**Arquivo:** `01-basico/main.go`

**O que vocÃª vai aprender:**
- Como fazer requisiÃ§Ãµes HTTP
- Como parsear HTML com goquery
- Tratamento de erros
- Timeouts

**Execute:**
```bash
go run cmd/aula-crawler/01-basico/main.go
```

**Resultado:** Crawler simples, mas LENTO ğŸŒ

---

### 2ï¸âƒ£ Exemplo Concorrente (30 minutos)
**Arquivo:** `02-concorrente/main.go`

**O que vocÃª vai aprender:**
- ğŸ”¥ **GOROUTINES** (o superpoder do Go!)
- Channels (comunicaÃ§Ã£o entre goroutines)
- WaitGroups (sincronizaÃ§Ã£o)
- Worker Pool Pattern

**Execute:**
```bash
go run cmd/aula-crawler/02-concorrente/main.go
```

**Resultado:** 4x mais rÃ¡pido! ğŸš€

---

### 3ï¸âƒ£ Exemplo Profissional (45 minutos)
**Arquivo:** `03-completo/main.go`

**O que vocÃª vai aprender:**
- Rate Limiting (controle por domÃ­nio)
- ExportaÃ§Ã£o para CSV
- MÃ©tricas avanÃ§adas
- Pronto para produÃ§Ã£o!

**Execute:**
```bash
go run cmd/aula-crawler/03-completo/main.go
```

**Resultado:** Crawler profissional com responsabilidade! ğŸ¯

---

## ğŸ“š DocumentaÃ§Ã£o Completa

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| [README.md](README.md) | Guia completo da aula |
| [GOROUTINES.md](GOROUTINES.md) | Tudo sobre Goroutines |
| Este arquivo | Quick Start |

---

## ğŸ¯ Conceitos Principais

### Goroutines em 1 Minuto

```go
// FunÃ§Ã£o normal (espera terminar)
minhaFuncao()

// Goroutine (roda em paralelo)
go minhaFuncao()
```

**Por que sÃ£o incrÃ­veis?**
- Thread normal: ~1MB de memÃ³ria
- Goroutine: ~2KB de memÃ³ria (500x menor!)
- VocÃª pode ter MILHÃ•ES rodando ao mesmo tempo

### Worker Pool em 1 Minuto

```go
// 1. Criar canais
jobs := make(chan string)
results := make(chan Result)

// 2. Criar workers
for i := 0; i < 5; i++ {
    go worker(jobs, results)
}

// 3. Enviar trabalhos
for _, url := range urls {
    jobs <- url
}
```

---

## ğŸ’¡ ComparaÃ§Ã£o Visual

```
EXEMPLO 1 (SÃ­ncrono):
URL1 â†’ URL2 â†’ URL3 â†’ URL4
â±ï¸  8 segundos

EXEMPLO 2 (4 Workers):
Worker1: URL1 â†’ URL5
Worker2: URL2 â†’ URL6
Worker3: URL3 â†’ URL7
Worker4: URL4 â†’ URL8
â±ï¸  2 segundos (4x mais rÃ¡pido!)

EXEMPLO 3 (Com Rate Limit):
Igual ao exemplo 2, mas:
âœ… Respeita servidores
âœ… Evita bloqueios
âœ… Profissional
```

---

## ğŸ“ PrÃ³ximos Passos

Depois de terminar os 3 exemplos:

1. âœ… Leia [GOROUTINES.md](GOROUTINES.md) para aprofundar
2. âœ… FaÃ§a os exercÃ­cios do [README.md](README.md)
3. âœ… Modifique os exemplos
4. âœ… Crie seu prÃ³prio crawler!

---

## ğŸ†˜ Problemas Comuns

### Erro: "package not found"
```bash
go mod tidy
go get github.com/PuerkitoBio/goquery
```

### Erro: "timeout"
```bash
# Aumente o timeout no cÃ³digo
client := http.Client{
    Timeout: 30 * time.Second, // Era 10s
}
```

### Erro: "too many open files"
```bash
# Reduza o nÃºmero de workers
workerCount := 3 // Era 5
```

---

## ğŸ“Š EstatÃ­sticas Esperadas

| Exemplo | URLs | Tempo | MemÃ³ria |
|---------|------|-------|---------|
| 01-basico | 4 | ~8s | 150MB |
| 02-concorrente | 8 | ~2s | 220MB |
| 03-completo | 10 | ~3s | 240MB |

---
