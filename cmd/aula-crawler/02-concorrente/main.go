package main

import (
	"fmt"
	"net/http"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
)

/*
===========================================
EXEMPLO 2: CRAWLER CONCORRENTE (GOROUTINES)
===========================================

Este exemplo usa GOROUTINES para processar m√∫ltiplas URLs ao mesmo tempo!

üî• CONCEITOS DE GOROUTINES:

1. O QUE S√ÉO GOROUTINES?
   - S√£o "threads leves" do Go
   - Muito mais baratas que threads do sistema operacional
   - Voc√™ pode ter milhares rodando ao mesmo tempo
   - Gerenciadas automaticamente pelo Go runtime

2. COMO FUNCIONAM?
   - Thread normal: ~1-2MB de mem√≥ria
   - Goroutine: ~2KB de mem√≥ria (500x menor!)
   - O Go usa um "scheduler" que distribui goroutines entre threads

3. COMO USAR?
   - Basta colocar "go" antes de uma fun√ß√£o
   - Exemplo: go minhaFuncao()
   - A fun√ß√£o roda em paralelo, sem bloquear

4. SINCRONIZA√á√ÉO:
   - WaitGroup: espera goroutines terminarem
   - Channels: comunica√ß√£o entre goroutines
   - Mutex: prote√ß√£o de dados compartilhados
*/

type Result struct {
	URL   string
	Title string
	H1    string
	Error error
}

// fetchAndParse busca uma URL e extrai informa√ß√µes
func fetchAndParse(url string) Result {
	client := http.Client{
		Timeout: 10 * time.Second,
	}

	resp, err := client.Get(url)
	if err != nil {
		return Result{URL: url, Error: err}
	}
	defer resp.Body.Close()

	doc, err := goquery.NewDocumentFromReader(resp.Body)
	if err != nil {
		return Result{URL: url, Error: err}
	}

	title := doc.Find("title").First().Text()
	h1 := doc.Find("h1").First().Text()

	return Result{
		URL:   url,
		Title: title,
		H1:    h1,
	}
}

// worker √© uma fun√ß√£o que processa URLs de um canal
func worker(id int, jobs <-chan string, results chan<- Result, wg *sync.WaitGroup) {
	// defer garante que Done() ser√° chamado quando a fun√ß√£o terminar
	defer wg.Done()

	// Loop infinito: processa URLs enquanto houver
	for url := range jobs {
		fmt.Printf("ü§ñ Worker %d processando: %s\n", id, url)
		result := fetchAndParse(url)
		results <- result // Envia resultado para o canal
	}

	fmt.Printf("üëã Worker %d finalizou!\n", id)
}

func main() {
	fmt.Println("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
	fmt.Println("‚ïë   WEB CRAWLER CONCORRENTE (GOROUTINES)   ‚ïë")
	fmt.Println("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
	fmt.Println()

	urls := []string{
		"https://golang.org",
		"https://go.dev",
		"https://github.com",
		"https://stackoverflow.com",
		"https://www.reddit.com",
		"https://news.ycombinator.com",
		"https://medium.com",
		"https://dev.to",
	}

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// PASSO 1: CRIAR OS CANAIS (CHANNELS)
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// Canais s√£o como "tubos" para passar dados entre goroutines

	// Canal de jobs: envia URLs para os workers
	jobs := make(chan string, len(urls))

	// Canal de results: recebe resultados dos workers
	results := make(chan Result, len(urls))

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// PASSO 2: CRIAR WAITGROUP
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// WaitGroup conta quantas goroutines ainda est√£o rodando
	var wg sync.WaitGroup

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// PASSO 3: CRIAR OS WORKERS (GOROUTINES)
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	workerCount := 4 // N√∫mero de workers simult√¢neos
	fmt.Printf("üöÄ Iniciando %d workers...\n\n", workerCount)

	startTime := time.Now()

	// Cria e inicia os workers
	for i := 1; i <= workerCount; i++ {
		wg.Add(1) // Incrementa o contador do WaitGroup
		go worker(i, jobs, results, &wg) // üî• AQUI EST√Å A M√ÅGICA!
		// A palavra "go" faz a fun√ß√£o rodar em paralelo!
	}

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// PASSO 4: ENVIAR JOBS PARA OS WORKERS
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	for _, url := range urls {
		jobs <- url // Envia URL para o canal
	}
	close(jobs) // Fecha o canal (n√£o haver√° mais jobs)

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// PASSO 5: COLETAR RESULTADOS
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// Esta goroutine fecha o canal de results quando todos os workers terminarem
	go func() {
		wg.Wait()      // Espera todos os workers terminarem
		close(results) // Fecha o canal de results
	}()

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// PASSO 6: PROCESSAR RESULTADOS
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	fmt.Println("\nüìä RESULTADOS:")
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")

	successCount := 0
	errorCount := 0

	// Range em canal: itera at√© o canal ser fechado
	for result := range results {
		if result.Error != nil {
			fmt.Printf("‚ùå %s\n   Erro: %v\n\n", result.URL, result.Error)
			errorCount++
		} else {
			fmt.Printf("‚úÖ %s\n", result.URL)
			fmt.Printf("   üìÑ T√≠tulo: %s\n", result.Title)
			fmt.Printf("   üìå H1: %s\n\n", result.H1)
			successCount++
		}
	}

	elapsed := time.Since(startTime)

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// ESTAT√çSTICAS
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	fmt.Println("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
	fmt.Printf("‚ïë   TEMPO TOTAL: %-24s  ‚ïë\n", elapsed)
	fmt.Printf("‚ïë   URLs PROCESSADAS: %-19d  ‚ïë\n", len(urls))
	fmt.Printf("‚ïë   Workers: %-28d  ‚ïë\n", workerCount)
	fmt.Printf("‚ïë   Sucessos: %-27d  ‚ïë\n", successCount)
	fmt.Printf("‚ïë   Erros: %-30d  ‚ïë\n", errorCount)
	fmt.Println("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
	fmt.Println()

	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	// EXPLICA√á√ÉO DA VELOCIDADE
	// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
	fmt.Println("üí° POR QUE √â MAIS R√ÅPIDO?")
	fmt.Println("   Exemplo com 4 workers e 8 URLs:")
	fmt.Println()
	fmt.Println("   ‚è±Ô∏è  S√≠ncrono (01-basico):")
	fmt.Println("      URL1 ‚Üí URL2 ‚Üí URL3 ‚Üí URL4 ‚Üí URL5 ‚Üí URL6 ‚Üí URL7 ‚Üí URL8")
	fmt.Println("      Se cada uma leva 2s = 16 segundos total")
	fmt.Println()
	fmt.Println("   üöÄ Concorrente (4 workers):")
	fmt.Println("      Worker 1: URL1 ‚Üí URL5")
	fmt.Println("      Worker 2: URL2 ‚Üí URL6")
	fmt.Println("      Worker 3: URL3 ‚Üí URL7")
	fmt.Println("      Worker 4: URL4 ‚Üí URL8")
	fmt.Println("      Todas rodando ao mesmo tempo = ~4 segundos!")
	fmt.Println()
	fmt.Println("   üìà GANHO: ~4x mais r√°pido com 4 workers!")
	fmt.Println()
	fmt.Println("‚ö†Ô∏è  PR√ìXIMO PASSO:")
	fmt.Println("    Adicionar rate limiting para n√£o sobrecarregar servidores")
	fmt.Println("    Execute: go run cmd/aula-crawler/03-completo/main.go")
}
